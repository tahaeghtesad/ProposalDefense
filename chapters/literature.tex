\chapter{Literature Review}
\label{chap:literature}

\iTaha{I have copy pasted these paragraphs from older papers.}

\section{Reinforcement Learning for cybersecurity}

Application of machine learning---especially \textit{deep reinforcement learning} (DRL)---for cybersecurity has gained attention recently. Nguyen~\ea~\cite{nguyen2019deep} surveyed current literature on applications of DRL on cybersecurity. These applications include: DRL-based security methods for cyber-physical systems, autonomous intrusion detection techniques~\cite{iannucci2019performance}, and multi-agent DRL-based game-theoretic simulations for defense strategies against cyber attacks.

For example, Malialis~\cite{malialis2015distributed,malialis2015distributed2} applied multi-agent deep reinforcement learning on network routers to throttle the processing rate in order to prevent \textit{distributed denial of service} (DDoS) attacks. Bhosale~\ea~\cite{bhosale2014cooperative} proposed a cooperative multi-agent reinforcement learning for intelligent systems~\cite{herrero2009multiagent} to enable quick responses. Another example for multi-agent reinforcement learning is the fuzzy $Q$-Learning approach for detecting and preventing intrusions in \textit{wireless sensor networks} (WSN)~\cite{shamshirband2014cooperative}. Furthermore, Tong~\ea~\cite{tong2019finding} proposed a multi-agent reinforcement learning framework for alert correlation based on double oracles.

\subsection{Reinforcement Learning for Moving Target Defense}

\subsection{Reinforcement Learning for False Information Injection}

\section{Model based mitigation}

\section{Reinforcement Learning Approaches}

The basics of deep reinforcement learning are described here: D$Q$L, DDPG, DSPG, TRPO, PPO.

\subsection{Multi-Agent Reinforcement Learning}

Deep Multi-Agent RL belongs here. MADDPG, QMix, etc.

\subsection{Hierarchical RL}

Hierarchical Reinforcement Learning (HRL) has gained significant attention due to its applications and development. These methods have proven to be successful in tasks that require coordination between multiple agents, such as Unnamed Aerial Vehicles (UAVs) and autonomous vehicles, to complete objectives efficiently.

For instance, Yang~\ea~\cite{yang2018hierarchical} devised a general framework for combining compound and basic tasks in robotics, such as navigation and motor functions, respectively. However, they limited the application to single-agent RL at both levels. Similarly, Chen et al. used attention networks to incorporate environmental data with steering functions of autonomous vehicles in a hierarchical RL manner so that the vehicle can safely and smoothly change lanes.

In the UAV applications, Zhang~\ea~\cite{zhang2020hierarchical} demonstrated the success of hierarchical RL in the coordination of wireless communication and data collection of UAVs.

Although our problem is in a different domain, the fundamental ideas of these works are applicable to us since we are dealing with cooperation and coordination between adversarial agents in finding an optimal manipulation strategy in navigation applications. The study results indicate that the use of Reinforcement Learning approaches accurately modeled the effects of false information injection on navigation apps.

\subsection{Graph Convoloutional Networks}

\section{Game Theory}